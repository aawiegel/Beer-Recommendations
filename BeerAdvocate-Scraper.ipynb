{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape BeerAdvocate for beer ratings\n",
    "This notebook scrapes BeerAdvocate for ratings of beer to subsequently perform linear regression on the ratings in terms of other available information on the beer. We start with the style page since we can use this to obtain a list of all beers of that style easily from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fake_useragent import UserAgent\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.beeradvocate.com\"\n",
    "start_url = base_url+\"/beer/style/\"\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "def download_parse_ba(style_file, url):\n",
    "    \"\"\"\n",
    "    sytle_file: file to be written (including subdirectory)\n",
    "    url: url to read from\n",
    "    Reads a url from BeerAdvocate.com and dumps\n",
    "    its main content into a local HTML file\n",
    "    \"\"\"\n",
    "    \n",
    "    user_agent = {'User-agent': ua.random}\n",
    "    \n",
    "    r = requests.get(url, headers = user_agent)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    main_content = soup.find(id='ba-content')\n",
    "    \n",
    "    with open(style_file, 'w') as file:\n",
    "        file.write(str(main_content))\n",
    "    \n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab first style file to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "styles = os.path.join(os.path.curdir, \"data\", \"styles.html\")\n",
    "\n",
    "if not os.path.exists(styles):\n",
    "    os.makedirs(\"data\")\n",
    "    r = requests.get(start_url)\n",
    "    page = r.text\n",
    "    with open(styles, 'w') as file:\n",
    "        file.write(page)\n",
    "else:\n",
    "    with open(styles, 'r') as file:\n",
    "        page = file.read()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type = Ale, Lager, or Hybrid\n",
    "type_tables = soup.find('table').findAll('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_link_dict = dict()\n",
    "for type_table in type_tables:\n",
    "    beer_type = type_table.find('span').text.split(\" \")[0]\n",
    "    style_link_dict[beer_type] = dict()\n",
    "    for style in type_table.findAll('a'):\n",
    "        style_name = \"\".join(style.text.split())\n",
    "        style_name = re.sub(\"/\", \"\", style_name)\n",
    "        style_name = re.sub(\"&\", \"And\", style_name)\n",
    "        style_name = style_name.split(\"(\")[0]\n",
    "        style_name = re.sub(\"è\", \"e\", style_name)\n",
    "        style_name = re.sub(\"ö\", \"o\", style_name)\n",
    "        style_name = re.sub(\"ä\", \"a\", style_name)\n",
    "        style_link_dict[beer_type][style_name] = base_url+style['href']\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FruitVegetableBeer': 'https://www.beeradvocate.com/beer/style/9/',\n",
       " 'HerbedSpicedBeer': 'https://www.beeradvocate.com/beer/style/8/',\n",
       " 'SmokedBeer': 'https://www.beeradvocate.com/beer/style/11/'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_link_dict['Hybrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab first page of each style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beer_type, styles in style_link_dict.items():\n",
    "    \n",
    "    beer_type_dir = os.path.join(os.path.curdir, \"data\", beer_type)\n",
    "    \n",
    "    if not os.path.exists(beer_type_dir):\n",
    "        os.makedirs(beer_type_dir)\n",
    "        \n",
    "    for style, url in styles.items():\n",
    "        style_type_dir = os.path.join(beer_type_dir, style)\n",
    "        if not os.path.exists(style_type_dir):\n",
    "            os.makedirs(style_type_dir)\n",
    "    \n",
    "        style_file = os.path.join(style_type_dir, style+\".html\")\n",
    "        \n",
    "        if not os.path.exists(style_file):\n",
    "            download_parse_ba(style_file, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22083"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n",
    "test_page = os.path.join(os.path.curdir, \"data\", \"Ale\", \"AmericanIPA\", \"AmericanIPA.html\")\n",
    "\n",
    "with open(test_page, 'r') as file:\n",
    "    page = file.read()\n",
    "    \n",
    "soup = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "beer_num = soup.find('table').find('span').find('b').text\n",
    "\n",
    "criteria = re.compile('\\w+\\)')\n",
    "\n",
    "found = re.search(criteria, beer_num)\n",
    "int(found.group(0).split(')')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab all pages that link to beer reviews based on first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-e509d529d337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mdownload_parse_ba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-cf8263089e4d>\u001b[0m in \u001b[0;36mdownload_parse_ba\u001b[0;34m(style_file, url)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for beer_type, styles in style_link_dict.items():\n",
    "    \n",
    "    beer_type_dir = os.path.join(os.path.curdir, \"data\", beer_type)\n",
    "    \n",
    "    for style, url in styles.items():\n",
    "        \n",
    "        style_type_dir = os.path.join(beer_type_dir, style)\n",
    "        \n",
    "        first_style_file = os.path.join(style_type_dir, style+\".html\")\n",
    "        \n",
    "        with open(first_style_file, 'r') as file:\n",
    "            page = file.read()\n",
    "    \n",
    "        soup = BeautifulSoup(page,\"lxml\")\n",
    "        \n",
    "        # Find number of beers for the style\n",
    "\n",
    "        beer_num_tag = soup.find('table').find('span').find('b').text\n",
    "\n",
    "        criteria = re.compile('\\w+\\)')\n",
    "\n",
    "        found = re.search(criteria, beer_num_tag)\n",
    "        review_count = int(found.group(0).split(')')[0])\n",
    "        \n",
    "        page_num = review_count // 50\n",
    "        \n",
    "        # Get all pages that link to reviews of beer\n",
    "        \n",
    "        for i in range(1,page_num+1):\n",
    "            \n",
    "            style_file = os.path.join(style_type_dir, style+str(i)+\".html\")\n",
    "            url_params = url + \"?sort=revsD&start=\"+str(i*50)\n",
    "            \n",
    "        \n",
    "            if not os.path.exists(style_file):\n",
    "                download_parse_ba(style_file, url_params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
